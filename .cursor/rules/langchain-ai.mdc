# LangChain & AI Agents Development Guidelines

## LangChain Framework Overview
- Use LangChain for building LLM-powered applications
- Implement proper prompt engineering and management
- Use LangGraph for complex, stateful workflows
- Implement proper tool integration and calling
- Use proper memory and context management

## Project Structure
```
ai/
  langchain/
    agents/           # AI agent implementations
    workflows/        # LangGraph workflow definitions
    tools/           # Custom tools and integrations
    prompts/         # Prompt templates and management
    memory/          # Memory and context management
    embeddings/      # Vector embeddings and RAG
    chains/          # LangChain chain implementations
  models/            # Model configurations and management
  data/              # Training data and datasets
  tests/             # AI system testing
```

## LangChain Core Components

### Prompt Management
```python
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate

# System prompt template
system_template = """You are an expert ERP system assistant. 
You help users with inventory management, sales, and business operations.
Always provide accurate, helpful information based on the context provided."""

system_prompt = SystemMessagePromptTemplate.from_template(system_template)

# Human prompt template
human_template = """User question: {question}
Context: {context}
Please provide a helpful response."""

human_prompt = HumanMessagePromptTemplate.from_template(human_template)

# Combined chat prompt
chat_prompt = ChatPromptTemplate.from_messages([system_prompt, human_prompt])
```

### Tool Integration
```python
from langchain.tools import BaseTool
from typing import Optional
from pydantic import BaseModel, Field

class InventoryLookupInput(BaseModel):
    product_id: str = Field(description="The product ID to look up")
    include_stock: bool = Field(default=True, description="Whether to include stock information")

class InventoryLookupTool(BaseTool):
    name = "inventory_lookup"
    description = "Look up product information and stock levels"
    args_schema = InventoryLookupInput
    
    def _run(self, product_id: str, include_stock: bool = True) -> str:
        # Implementation for inventory lookup
        product = self.inventory_service.get_product(product_id)
        if include_stock:
            stock = self.inventory_service.get_stock_level(product_id)
            return f"Product: {product.name}, Stock: {stock.quantity}"
        return f"Product: {product.name}"
    
    async def _arun(self, product_id: str, include_stock: bool = True) -> str:
        # Async implementation
        return await self._run(product_id, include_stock)
```

## LangGraph Workflow Implementation

### State Management
```python
from typing import TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolExecutor

# Define workflow state
class WorkflowState(TypedDict):
    messages: Annotated[list, "The messages in the conversation"]
    current_step: Annotated[str, "The current step in the workflow"]
    context: Annotated[dict, "Additional context for the workflow"]
    result: Annotated[Optional[str], "The result of the workflow"]

# Create workflow graph
def create_erp_workflow():
    workflow = StateGraph(WorkflowState)
    
    # Add nodes
    workflow.add_node("analyze_request", analyze_user_request)
    workflow.add_node("gather_context", gather_relevant_context)
    workflow.add_node("execute_action", execute_business_action)
    workflow.add_node("format_response", format_response_for_user)
    
    # Define edges
    workflow.add_edge("analyze_request", "gather_context")
    workflow.add_edge("gather_context", "execute_action")
    workflow.add_edge("execute_action", "format_response")
    workflow.add_edge("format_response", END)
    
    # Add conditional edges for error handling
    workflow.add_conditional_edges(
        "analyze_request",
        should_continue_or_error,
        {
            "continue": "gather_context",
            "error": "format_response"
        }
    )
    
    return workflow.compile()

# Node functions
def analyze_user_request(state: WorkflowState) -> WorkflowState:
    """Analyze the user's request and determine the required actions."""
    messages = state["messages"]
    last_message = messages[-1].content
    
    # Analyze the request using LLM
    analysis = llm.invoke(f"Analyze this ERP request: {last_message}")
    
    state["context"]["analysis"] = analysis
    state["current_step"] = "gather_context"
    return state

def gather_relevant_context(state: WorkflowState) -> WorkflowState:
    """Gather relevant context from various data sources."""
    analysis = state["context"]["analysis"]
    
    # Use tools to gather context
    context = {}
    if "inventory" in analysis.lower():
        context["inventory"] = inventory_tool.run(analysis)
    if "sales" in analysis.lower():
        context["sales"] = sales_tool.run(analysis)
    
    state["context"]["gathered_context"] = context
    state["current_step"] = "execute_action"
    return state
```

## AI Agent Implementation

### Agent Definition
```python
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.agents.openai_functions_agent.base import OpenAIFunctionsAgent
from langchain.schema import AgentAction, AgentFinish

class ERPAssistantAgent:
    def __init__(self, llm, tools, memory):
        self.llm = llm
        self.tools = tools
        self.memory = memory
        self.tool_executor = ToolExecutor(tools)
        
        # Create the agent
        self.agent = create_openai_functions_agent(
            llm=llm,
            tools=tools,
            prompt=self.create_prompt()
        )
        
        # Create the executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=tools,
            memory=memory,
            verbose=True,
            handle_parsing_errors=True
        )
    
    def create_prompt(self):
        return ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(
                """You are an intelligent ERP system assistant. You help users with:
                - Inventory management
                - Sales operations
                - Customer relationship management
                - Financial operations
                - Business analytics
                
                Always provide accurate, helpful information and use the appropriate tools when needed."""
            ),
            MessagesPlaceholder(variable_name="chat_history"),
            HumanMessagePromptTemplate.from_template("{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])
    
    async def process_request(self, user_input: str) -> str:
        """Process a user request using the agent."""
        try:
            result = await self.agent_executor.ainvoke({
                "input": user_input,
                "chat_history": self.memory.chat_memory.messages
            })
            return result["output"]
        except Exception as e:
            return f"I encountered an error: {str(e)}. Please try rephrasing your request."
```

## RAG (Retrieval-Augmented Generation) Implementation

### Vector Database Integration
```python
from langchain.vectorstores import Chroma, Pinecone
from langchain.embeddings import OpenAIEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.document_loaders import TextLoader, DirectoryLoader

class ERPRAGSystem:
    def __init__(self, vector_store_type="chroma"):
        self.embeddings = OpenAIEmbeddings()
        self.vector_store_type = vector_store_type
        self.vector_store = None
        self.retriever = None
        
    def setup_vector_store(self, documents_path: str):
        """Set up the vector store with ERP documents."""
        # Load documents
        loader = DirectoryLoader(
            documents_path,
            glob="**/*.txt",
            loader_cls=TextLoader
        )
        documents = loader.load()
        
        # Split documents
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # Create vector store
        if self.vector_store_type == "chroma":
            self.vector_store = Chroma.from_documents(
                documents=splits,
                embedding=self.embeddings
            )
        elif self.vector_store_type == "pinecone":
            self.vector_store = Pinecone.from_documents(
                documents=splits,
                embedding=self.embeddings,
                index_name="erp-knowledge"
            )
        
        self.retriever = self.vector_store.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}
        )
    
    def retrieve_relevant_context(self, query: str) -> list:
        """Retrieve relevant context for a query."""
        if not self.retriever:
            raise ValueError("Vector store not initialized")
        
        docs = self.retriever.get_relevant_documents(query)
        return [doc.page_content for doc in docs]
    
    def generate_response(self, query: str, context: list) -> str:
        """Generate a response using the retrieved context."""
        context_text = "\n\n".join(context)
        
        prompt = f"""Based on the following context, answer the user's question:

Context:
{context_text}

Question: {query}

Answer:"""
        
        response = self.llm.invoke(prompt)
        return response.content
```

## Multi-Agent Workflows

### Agent Orchestration
```python
from langchain.agents import AgentExecutor
from langchain.schema import AgentAction, AgentFinish
from typing import List, Dict, Any

class MultiAgentOrchestrator:
    def __init__(self, agents: Dict[str, AgentExecutor]):
        self.agents = agents
        self.conversation_history = []
    
    async def orchestrate_workflow(self, user_request: str) -> str:
        """Orchestrate a multi-agent workflow."""
        # Step 1: Route to appropriate agent
        routing_agent = self.agents["router"]
        routing_result = await routing_agent.ainvoke({
            "input": f"Route this request to the appropriate agent: {user_request}"
        })
        
        target_agent_name = self.extract_agent_name(routing_result["output"])
        target_agent = self.agents.get(target_agent_name)
        
        if not target_agent:
            return f"Unable to route request to agent: {target_agent_name}"
        
        # Step 2: Execute with target agent
        agent_result = await target_agent.ainvoke({
            "input": user_request,
            "conversation_history": self.conversation_history
        })
        
        # Step 3: Update conversation history
        self.conversation_history.append({
            "user": user_request,
            "agent": target_agent_name,
            "response": agent_result["output"]
        })
        
        return agent_result["output"]
    
    def extract_agent_name(self, routing_output: str) -> str:
        """Extract agent name from routing output."""
        # Simple extraction logic - could be enhanced with LLM parsing
        if "inventory" in routing_output.lower():
            return "inventory_agent"
        elif "sales" in routing_output.lower():
            return "sales_agent"
        elif "crm" in routing_output.lower():
            return "crm_agent"
        else:
            return "general_agent"
```

## Integration with .NET Services

### C# LangChain Integration
```csharp
using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Plugins.Core;
using Microsoft.SemanticKernel.Connectors.OpenAI;

public class LangChainIntegrationService
{
    private readonly Kernel _kernel;
    private readonly ILogger<LangChainIntegrationService> _logger;
    
    public LangChainIntegrationService(IConfiguration configuration, ILogger<LangChainIntegrationService> logger)
    {
        _logger = logger;
        
        var builder = Kernel.CreateBuilder();
        builder.AddOpenAIChatCompletion(
            modelId: configuration["OpenAI:ModelId"]!,
            apiKey: configuration["OpenAI:ApiKey"]!
        );
        
        _kernel = builder.Build();
    }
    
    public async Task<string> ProcessRequestAsync(string userRequest, string context)
    {
        try
        {
            var prompt = $@"Based on the following context, answer the user's request:

Context: {context}

User Request: {userRequest}

Please provide a helpful and accurate response:";
            
            var result = await _kernel.InvokePromptAsync(prompt);
            return result.ToString();
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error processing LangChain request");
            return "I encountered an error processing your request. Please try again.";
        }
    }
    
    public async Task<string> GenerateResponseWithToolsAsync(string userRequest, IEnumerable<string> availableTools)
    {
        var tools = string.Join(", ", availableTools);
        
        var prompt = $@"You have access to the following tools: {tools}

User Request: {userRequest}

Please determine which tool(s) to use and provide a response. If no tools are needed, provide a direct answer.";
        
        var result = await _kernel.InvokePromptAsync(prompt);
        return result.ToString();
    }
}
```

## Testing AI Systems

### Agent Testing
```python
import pytest
from unittest.mock import Mock, patch
from langchain.schema import HumanMessage, AIMessage

class TestERPAssistantAgent:
    @pytest.fixture
    def mock_llm(self):
        return Mock()
    
    @pytest.fixture
    def mock_tools(self):
        return [Mock(), Mock()]
    
    @pytest.fixture
    def agent(self, mock_llm, mock_tools):
        return ERPAssistantAgent(mock_llm, mock_tools, Mock())
    
    def test_agent_initialization(self, agent):
        assert agent.agent is not None
        assert agent.agent_executor is not None
    
    @patch('langchain.agents.AgentExecutor.invoke')
    def test_process_request_success(self, mock_invoke, agent):
        mock_invoke.return_value = {"output": "Success response"}
        
        result = agent.process_request("Test request")
        assert result == "Success response"
    
    @patch('langchain.agents.AgentExecutor.invoke')
    def test_process_request_error(self, mock_invoke, agent):
        mock_invoke.side_effect = Exception("Test error")
        
        result = agent.process_request("Test request")
        assert "error" in result.lower()
```

## Performance Optimization

### Caching and Optimization
```python
from functools import lru_cache
from langchain.cache import InMemoryCache
import langchain

# Enable caching
langchain.cache = InMemoryCache()

class OptimizedERPAgent:
    def __init__(self):
        self.response_cache = {}
        self.context_cache = {}
    
    @lru_cache(maxsize=1000)
    def get_cached_response(self, query_hash: str) -> str:
        """Get cached response for a query."""
        return self.response_cache.get(query_hash)
    
    def cache_response(self, query_hash: str, response: str):
        """Cache a response for future use."""
        self.response_cache[query_hash] = response
    
    async def process_request_optimized(self, user_input: str) -> str:
        """Process request with caching optimization."""
        query_hash = hash(user_input)
        
        # Check cache first
        cached_response = self.get_cached_response(query_hash)
        if cached_response:
            return cached_response
        
        # Process request
        response = await self.process_request(user_input)
        
        # Cache response
        self.cache_response(query_hash, response)
        
        return response
```

## Security and Safety

### Input Validation and Safety
```python
from langchain.safety import SafetyChecker
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
import re

class SafeERPAgent:
    def __init__(self):
        self.safety_checker = SafetyChecker()
        self.output_parser = self.create_output_parser()
    
    def create_output_parser(self):
        response_schemas = [
            ResponseSchema(name="response", description="The response to the user"),
            ResponseSchema(name="confidence", description="Confidence level 0-1"),
            ResponseSchema(name="requires_approval", description="Whether this requires human approval")
        ]
        return StructuredOutputParser.from_response_schemas(response_schemas)
    
    def validate_input(self, user_input: str) -> bool:
        """Validate user input for safety and appropriateness."""
        # Check for potentially harmful content
        harmful_patterns = [
            r"delete.*all",
            r"drop.*database",
            r"shutdown.*system"
        ]
        
        for pattern in harmful_patterns:
            if re.search(pattern, user_input.lower()):
                return False
        
        return True
    
    async def process_request_safe(self, user_input: str) -> str:
        """Process request with safety checks."""
        if not self.validate_input(user_input):
            return "I cannot process this request as it may be unsafe or inappropriate."
        
        # Process with safety checker
        safety_result = await self.safety_checker.check(user_input)
        if not safety_result.is_safe:
            return "I cannot process this request due to safety concerns."
        
        # Process normally
        return await self.process_request(user_input)
```

## Monitoring and Observability

### AI System Monitoring
```python
import logging
from datetime import datetime
from typing import Dict, Any

class AIAgentMonitor:
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "average_response_time": 0.0
        }
    
    def log_request(self, user_input: str, response: str, response_time: float):
        """Log a request and update metrics."""
        self.metrics["total_requests"] += 1
        self.metrics["successful_requests"] += 1
        
        # Update average response time
        current_avg = self.metrics["average_response_time"]
        total_requests = self.metrics["total_requests"]
        self.metrics["average_response_time"] = (
            (current_avg * (total_requests - 1) + response_time) / total_requests
        )
        
        # Log the request
        self.logger.info(
            f"Request processed successfully. "
            f"Input: {user_input[:100]}... "
            f"Response time: {response_time:.2f}s"
        )
    
    def log_error(self, user_input: str, error: Exception):
        """Log an error and update metrics."""
        self.metrics["total_requests"] += 1
        self.metrics["failed_requests"] += 1
        
        self.logger.error(
            f"Request failed. Input: {user_input[:100]}... Error: {str(error)}"
        )
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current metrics."""
        return self.metrics.copy()
```

## Best Practices Summary

### Development Guidelines
- Use proper prompt engineering and management
- Implement comprehensive error handling
- Use proper testing strategies for AI systems
- Implement proper security and safety measures
- Use proper monitoring and observability
- Optimize for performance and caching
- Follow proper documentation standards

### Integration Guidelines
- Use proper API design for AI services
- Implement proper authentication and authorization
- Use proper error handling and logging
- Implement proper rate limiting and throttling
- Use proper monitoring and alerting
- Follow proper deployment strategies
description: Comprehensive LangChain and AI agents guidelines for building intelligent workflows, RAG systems, and AI-powered applications
globs: **/*.py, **/*.cs, **/requirements.txt, **/Dockerfile, **/langchain/**/*, **/agents/**/*
alwaysApply: true
---
