apiVersion: v1
kind: ConfigMap
metadata:
  name: toss-ai-config
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
    version: v1.0.0
data:
  appsettings.json: |
    {
      "Logging": {
        "LogLevel": {
          "Default": "Information",
          "Microsoft.AspNetCore": "Warning"
        }
      },
      "AI": {
        "Platform": {
          "DefaultModelTimeout": "00:05:00",
          "MaxConcurrentInferences": 100,
          "EnableModelCaching": true,
          "CacheExpirationMinutes": 60,
          "DefaultPricingTier": "Standard"
        },
        "Security": {
          "EnableContentFiltering": true,
          "EnableInputValidation": true,
          "MaxInputSize": 1048576,
          "EnableAuditLogging": true
        },
        "Quotas": {
          "DefaultMonthlyCredits": 10000,
          "DefaultMaxTokensPerRequest": 4000,
          "DefaultMaxRequestsPerMinute": 100
        }
      },
      "Azure": {
        "CognitiveServices": {
          "Endpoint": "https://toss-cognitive.cognitiveservices.azure.com/",
          "Region": "eastus"
        },
        "OpenAI": {
          "Endpoint": "https://toss-openai.openai.azure.com/",
          "ApiVersion": "2024-02-01"
        }
      },
      "ConnectionStrings": {
        "DefaultConnection": "Host=toss-postgres-primary.toss-ai.svc.cluster.local;Database=TossAI;Username=toss_ai_user;Password=$(POSTGRES_PASSWORD)",
        "Redis": "toss-redis.toss-ai.svc.cluster.local:6379"
      }
    }

---
apiVersion: v1
kind: Secret
metadata:
  name: toss-ai-secrets
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
type: Opaque
data:
  # These will be populated by Azure Key Vault CSI driver
  azure-cognitive-services-key: ""
  azure-openai-key: ""
  postgres-password: ""
  redis-password: ""
  jwt-signing-key: ""

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: toss-ai-service
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
    version: v1.0.0
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: toss-ai
      component: ai-service
  template:
    metadata:
      labels:
        app: toss-ai
        component: ai-service
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: toss-ai-service-account
      automountServiceAccountToken: true
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 3000
      containers:
      - name: ai-service
        image: tossacr.azurecr.io/toss/ai-service:latest
        imagePullPolicy: Always
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: grpc
          containerPort: 9090
          protocol: TCP
        env:
        - name: ASPNETCORE_ENVIRONMENT
          value: "Production"
        - name: ASPNETCORE_URLS
          value: "http://+:8080;http://+:9090"
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: postgres-password
        - name: AZURE_COGNITIVE_SERVICES_KEY
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: azure-cognitive-services-key
        - name: AZURE_OPENAI_KEY
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: azure-openai-key
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: redis-password
        - name: JWT_SIGNING_KEY
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: jwt-signing-key
        volumeMounts:
        - name: config-volume
          mountPath: /app/appsettings.json
          subPath: appsettings.json
          readOnly: true
        - name: secrets-store
          mountPath: /mnt/secrets-store
          readOnly: true
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: http
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 5
          periodSeconds: 5
          timeoutSeconds: 3
          failureThreshold: 3
        startupProbe:
          httpGet:
            path: /ready
            port: http
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 30
      volumes:
      - name: config-volume
        configMap:
          name: toss-ai-config
      - name: secrets-store
        csi:
          driver: secrets-store.csi.k8s.io
          readOnly: true
          volumeAttributes:
            secretProviderClass: toss-ai-secrets
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - toss-ai
                - key: component
                  operator: In
                  values:
                  - ai-service
              topologyKey: kubernetes.io/hostname
      nodeSelector:
        node-type: application
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "application"
        effect: "NoSchedule"

---
apiVersion: v1
kind: Service
metadata:
  name: toss-ai-service
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
  annotations:
    service.beta.kubernetes.io/azure-load-balancer-internal: "true"
spec:
  type: LoadBalancer
  selector:
    app: toss-ai
    component: ai-service
  ports:
  - name: http
    port: 80
    targetPort: http
    protocol: TCP
  - name: grpc
    port: 9090
    targetPort: grpc
    protocol: TCP

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: toss-ai-inference-worker
  namespace: toss-ai
  labels:
    app: toss-ai
    component: inference-worker
    version: v1.0.0
spec:
  replicas: 2
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 0
      maxSurge: 2
  selector:
    matchLabels:
      app: toss-ai
      component: inference-worker
  template:
    metadata:
      labels:
        app: toss-ai
        component: inference-worker
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
    spec:
      serviceAccountName: toss-ai-service-account
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 3000
      containers:
      - name: inference-worker
        image: tossacr.azurecr.io/toss/ai-inference-worker:latest
        imagePullPolicy: Always
        ports:
        - name: metrics
          containerPort: 8080
          protocol: TCP
        env:
        - name: ASPNETCORE_ENVIRONMENT
          value: "Production"
        - name: AZURE_COGNITIVE_SERVICES_KEY
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: azure-cognitive-services-key
        - name: AZURE_OPENAI_KEY
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: azure-openai-key
        - name: REDIS_PASSWORD
          valueFrom:
            secretKeyRef:
              name: toss-ai-secrets
              key: redis-password
        volumeMounts:
        - name: config-volume
          mountPath: /app/appsettings.json
          subPath: appsettings.json
          readOnly: true
        - name: model-cache
          mountPath: /app/models
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
            nvidia.com/gpu: "0"
          limits:
            memory: "4Gi"
            cpu: "2000m"
            nvidia.com/gpu: "1"
        livenessProbe:
          httpGet:
            path: /health
            port: metrics
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        readinessProbe:
          httpGet:
            path: /ready
            port: metrics
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
      volumes:
      - name: config-volume
        configMap:
          name: toss-ai-config
      - name: model-cache
        emptyDir:
          sizeLimit: 50Gi
      nodeSelector:
        node-type: ai-workload
        accelerator: nvidia-gpu
      tolerations:
      - key: "dedicated"
        operator: "Equal"
        value: "ai-workload"
        effect: "NoSchedule"
      - key: "nvidia.com/gpu"
        operator: "Exists"
        effect: "NoSchedule"

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: toss-ai-service-hpa
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: toss-ai-service
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: ai_inference_requests_per_second
      target:
        type: AverageValue
        averageValue: "50"
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
      - type: Pods
        value: 4
        periodSeconds: 15
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
      selectPolicy: Min

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: toss-ai-inference-worker-hpa
  namespace: toss-ai
  labels:
    app: toss-ai
    component: inference-worker
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: toss-ai-inference-worker
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 75
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 85
  - type: Resource
    resource:
      name: nvidia.com/gpu
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleUp:
      stabilizationWindowSeconds: 600
      policies:
      - type: Pods
        value: 2
        periodSeconds: 60
      selectPolicy: Max
    scaleDown:
      stabilizationWindowSeconds: 600
      policies:
      - type: Pods
        value: 1
        periodSeconds: 120
      selectPolicy: Min

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: toss-ai-service-account
  namespace: toss-ai
  labels:
    app: toss-ai
  annotations:
    azure.workload.identity/client-id: "$(AZURE_CLIENT_ID)"

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: toss-ai-service-pdb
  namespace: toss-ai
  labels:
    app: toss-ai
    component: ai-service
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: toss-ai
      component: ai-service

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: toss-ai-inference-worker-pdb
  namespace: toss-ai
  labels:
    app: toss-ai
    component: inference-worker
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: toss-ai
      component: inference-worker

---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: toss-ai-network-policy
  namespace: toss-ai
  labels:
    app: toss-ai
spec:
  podSelector:
    matchLabels:
      app: toss-ai
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: toss-gateway
    - namespaceSelector:
        matchLabels:
          name: toss-monitoring
    - podSelector:
        matchLabels:
          app: toss-ai
    ports:
    - protocol: TCP
      port: 8080
    - protocol: TCP
      port: 9090
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: toss-data
    ports:
    - protocol: TCP
      port: 5432
    - protocol: TCP
      port: 6379
  - to: []
    ports:
    - protocol: TCP
      port: 443
    - protocol: TCP
      port: 53
    - protocol: UDP
      port: 53
